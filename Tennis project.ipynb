{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This project was completed during my 1st-year university break (end of 2017). Improvements to be added in the future.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The aim of this project was to build a machine learning model that can accurately predict the winner of a men's tennis match. I obtained data for ATP matches played between 1995-2017 from Jeff Sackman's Github repository (https://github.com/JeffSackmann/tennis_atp).\n",
    "\n",
    "There were 3 key stages to this project:\n",
    "1. Data preparation (merging files, cleaning data and dealing with missing values)\n",
    "2. Feature engineering (creating new informative features using my domain knowledge of tennis)\n",
    "3. Modelling (training classification algorithms and evaluating their performance)\n",
    "\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sort each csv file by date and merge them all into one file\n",
    "\n",
    "df = pd.read_csv(\"atp_matches_2017.csv\", usecols=range(49), index_col = False)\n",
    "df.sort_values(by='tourney_date', ascending=False, na_position='first', inplace = True)\n",
    "df_whole = df\n",
    "\n",
    "for i in range(2016, 1994, -1):    \n",
    "    df = pd.read_csv(\"atp_matches_\" + str(i) + \".csv\", usecols=range(49), index_col = False)\n",
    "    df.sort_values(by='tourney_date', ascending=False, na_position='first', inplace = True)\n",
    "    df_whole = pd.concat([df_whole, df])\n",
    "    \n",
    "# Save the merged file\n",
    "df_whole.to_csv(\"atp_matches.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>surface</th>\n",
       "      <th>draw_size</th>\n",
       "      <th>tourney_level</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>match_num</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>winner_seed</th>\n",
       "      <th>winner_entry</th>\n",
       "      <th>...</th>\n",
       "      <th>w_bpFaced</th>\n",
       "      <th>l_ace</th>\n",
       "      <th>l_df</th>\n",
       "      <th>l_svpt</th>\n",
       "      <th>l_1stIn</th>\n",
       "      <th>l_1stWon</th>\n",
       "      <th>l_2ndWon</th>\n",
       "      <th>l_SvGms</th>\n",
       "      <th>l_bpSaved</th>\n",
       "      <th>l_bpFaced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-560</td>\n",
       "      <td>Us Open</td>\n",
       "      <td>Hard</td>\n",
       "      <td>128</td>\n",
       "      <td>G</td>\n",
       "      <td>20170828</td>\n",
       "      <td>156</td>\n",
       "      <td>106298</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-560</td>\n",
       "      <td>Us Open</td>\n",
       "      <td>Hard</td>\n",
       "      <td>128</td>\n",
       "      <td>G</td>\n",
       "      <td>20170828</td>\n",
       "      <td>124</td>\n",
       "      <td>105138</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-560</td>\n",
       "      <td>Us Open</td>\n",
       "      <td>Hard</td>\n",
       "      <td>128</td>\n",
       "      <td>G</td>\n",
       "      <td>20170828</td>\n",
       "      <td>206</td>\n",
       "      <td>103893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-560</td>\n",
       "      <td>Us Open</td>\n",
       "      <td>Hard</td>\n",
       "      <td>128</td>\n",
       "      <td>G</td>\n",
       "      <td>20170828</td>\n",
       "      <td>205</td>\n",
       "      <td>104999</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-560</td>\n",
       "      <td>Us Open</td>\n",
       "      <td>Hard</td>\n",
       "      <td>128</td>\n",
       "      <td>G</td>\n",
       "      <td>20170828</td>\n",
       "      <td>204</td>\n",
       "      <td>105023</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n",
       "0   2017-560      Us Open    Hard        128             G      20170828   \n",
       "1   2017-560      Us Open    Hard        128             G      20170828   \n",
       "2   2017-560      Us Open    Hard        128             G      20170828   \n",
       "3   2017-560      Us Open    Hard        128             G      20170828   \n",
       "4   2017-560      Us Open    Hard        128             G      20170828   \n",
       "\n",
       "   match_num  winner_id  winner_seed winner_entry    ...    w_bpFaced l_ace  \\\n",
       "0        156     106298         16.0          NaN    ...          8.0   3.0   \n",
       "1        124     105138         11.0          NaN    ...         16.0  11.0   \n",
       "2        206     103893          NaN          NaN    ...          9.0   1.0   \n",
       "3        205     104999         23.0          NaN    ...          3.0  11.0   \n",
       "4        204     105023         17.0          NaN    ...          2.0   5.0   \n",
       "\n",
       "   l_df l_svpt  l_1stIn  l_1stWon  l_2ndWon  l_SvGms  l_bpSaved l_bpFaced  \n",
       "0   3.0   90.0     57.0      37.0      19.0      0.0        5.0       8.0  \n",
       "1   3.0  120.0     69.0      50.0      19.0      0.0        8.0      14.0  \n",
       "2   2.0   87.0     52.0      27.0      16.0      0.0        4.0      12.0  \n",
       "3   7.0  101.0     67.0      51.0      13.0      0.0        2.0       5.0  \n",
       "4   4.0  106.0     78.0      54.0      15.0      0.0        5.0       9.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv(\"atp_matches.csv\", usecols = range(49), index_col = False)\n",
    "\n",
    "# Display the first 5 rows of the dataset, to give a preview of the data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tourney_id             object\n",
      "tourney_name           object\n",
      "surface                object\n",
      "draw_size               int64\n",
      "tourney_level          object\n",
      "tourney_date            int64\n",
      "match_num               int64\n",
      "winner_id               int64\n",
      "winner_seed           float64\n",
      "winner_entry           object\n",
      "winner_name            object\n",
      "winner_hand            object\n",
      "winner_ht             float64\n",
      "winner_ioc             object\n",
      "winner_age            float64\n",
      "winner_rank           float64\n",
      "winner_rank_points    float64\n",
      "loser_id                int64\n",
      "loser_seed            float64\n",
      "loser_entry            object\n",
      "loser_name             object\n",
      "loser_hand             object\n",
      "loser_ht              float64\n",
      "loser_ioc              object\n",
      "loser_age             float64\n",
      "loser_rank            float64\n",
      "loser_rank_points     float64\n",
      "score                  object\n",
      "best_of                 int64\n",
      "round                  object\n",
      "minutes               float64\n",
      "w_ace                 float64\n",
      "w_df                  float64\n",
      "w_svpt                float64\n",
      "w_1stIn               float64\n",
      "w_1stWon              float64\n",
      "w_2ndWon              float64\n",
      "w_SvGms               float64\n",
      "w_bpSaved             float64\n",
      "w_bpFaced             float64\n",
      "l_ace                 float64\n",
      "l_df                  float64\n",
      "l_svpt                float64\n",
      "l_1stIn               float64\n",
      "l_1stWon              float64\n",
      "l_2ndWon              float64\n",
      "l_SvGms               float64\n",
      "l_bpSaved             float64\n",
      "l_bpFaced             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print a list of variable names, along with their data types\n",
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having a quick look at the data, I began the data cleaning process. First, I went through the features (using my knowledge of tennis along with descriptions of the variables) and got rid of ones that were irrelevant to this project. Getting rid of irrelevant variables will prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R32     23820\n",
       "R16     12435\n",
       "R64     11286\n",
       "RR       7988\n",
       "R128     7072\n",
       "QF       6238\n",
       "SF       3170\n",
       "F        1615\n",
       "BR          6\n",
       "Name: round, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete irrelevant variables\n",
    "df.drop(['draw_size', 'winner_seed','winner_entry', 'winner_ioc','loser_seed','loser_entry','loser_ioc'], axis=1, inplace=True)\n",
    "\n",
    "# Print unique values of the 'round' variable, with corresponding frequencies\n",
    "df['round'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then renamed the 'round' variable as 'stage' and numerically encoded it as follows:\n",
    "- 0 for a non-final\n",
    "- 1 for a quarter-final\n",
    "- 2 for a semi-final\n",
    "- 3 for a final\n",
    "\n",
    "This numerical encoding reflects the fact that it is progressively harder to win matches as a player progresses through a tournament.\n",
    "\n",
    "\"BR\" represents that the match was a bronze medal playoff in the Olympic Games. These matches are similar to semi-finals (in terms of the stage at which they are played during the tournament), so I changed all \"BR\" values to \"SF\" for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change \"BR\" to \"SF\"\n",
    "df.loc[df['round'] == \"BR\", 'round'] = \"SF\"\n",
    "\n",
    "# Rename the \"round\" variable\n",
    "df.rename(columns = { 'round' : 'stage'}, inplace = True)\n",
    "\n",
    "# Encode the categorical variable \"stage\"\n",
    "mapping_dict = {\n",
    "    \"stage\": {\n",
    "        \"RR\": 0,\n",
    "        \"R128\": 0,\n",
    "        \"R64\": 0,\n",
    "        \"R32\": 0,\n",
    "        \"R16\": 0,\n",
    "        \"QF\": 1,\n",
    "        \"SF\": 2,\n",
    "        \"F\": 3}\n",
    "}\n",
    "df = df.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_id               0\n",
       "tourney_name             0\n",
       "surface                210\n",
       "tourney_level            0\n",
       "tourney_date             0\n",
       "match_num                0\n",
       "winner_id                0\n",
       "winner_name              0\n",
       "winner_hand             14\n",
       "winner_ht             4330\n",
       "winner_age              28\n",
       "winner_rank           1723\n",
       "winner_rank_points    1723\n",
       "loser_id                 0\n",
       "loser_name               0\n",
       "loser_hand              31\n",
       "loser_ht              7173\n",
       "loser_age               65\n",
       "loser_rank            2667\n",
       "loser_rank_points     2667\n",
       "score                    2\n",
       "best_of                  0\n",
       "stage                    0\n",
       "minutes               9572\n",
       "w_ace                 7801\n",
       "w_df                  7801\n",
       "w_svpt                7801\n",
       "w_1stIn               7801\n",
       "w_1stWon              7801\n",
       "w_2ndWon              7801\n",
       "w_SvGms               7801\n",
       "w_bpSaved             7801\n",
       "w_bpFaced             7801\n",
       "l_ace                 7801\n",
       "l_df                  7801\n",
       "l_svpt                7801\n",
       "l_1stIn               7801\n",
       "l_1stWon              7801\n",
       "l_2ndWon              7801\n",
       "l_SvGms               7801\n",
       "l_bpSaved             7801\n",
       "l_bpFaced             7801\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no reasonable way to estimate missing values from certain variables (e.g. score) so any rows that had missing values for these variables were deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tourney_id               0\n",
       "tourney_name             0\n",
       "surface                 61\n",
       "tourney_level            0\n",
       "tourney_date             0\n",
       "match_num                0\n",
       "winner_id                0\n",
       "winner_name              0\n",
       "winner_hand              0\n",
       "winner_ht             2020\n",
       "winner_age               2\n",
       "winner_rank              0\n",
       "winner_rank_points       0\n",
       "loser_id                 0\n",
       "loser_name               0\n",
       "loser_hand               3\n",
       "loser_ht              3541\n",
       "loser_age               11\n",
       "loser_rank               0\n",
       "loser_rank_points        0\n",
       "score                    0\n",
       "best_of                  0\n",
       "stage                    0\n",
       "minutes               1857\n",
       "w_ace                    0\n",
       "w_df                     0\n",
       "w_svpt                   0\n",
       "w_1stIn                  0\n",
       "w_1stWon                 0\n",
       "w_2ndWon                 0\n",
       "w_SvGms                  0\n",
       "w_bpSaved                0\n",
       "w_bpFaced                0\n",
       "l_ace                    0\n",
       "l_df                     0\n",
       "l_svpt                   0\n",
       "l_1stIn                  0\n",
       "l_1stWon                 0\n",
       "l_2ndWon                 0\n",
       "l_SvGms                  0\n",
       "l_bpSaved                0\n",
       "l_bpFaced                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows that have missing values in specified columns\n",
    "df.dropna(subset = ['w_svpt','score','winner_rank','loser_rank'], inplace = True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 61 missing values for the surface variable, so I inputted these manually by looking up the matches online. I've omitted the code from this notebook for brevity, but here is an example of how I did it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tourney_id</th>\n",
       "      <th>tourney_name</th>\n",
       "      <th>tourney_date</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>2017-M-DC-2017-G1-AO-M-TPE-CHN-01</td>\n",
       "      <td>Davis Cup G1 R1: TPE vs CHN</td>\n",
       "      <td>20170217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>2017-M-DC-2017-G1-AO-M-TPE-CHN-01</td>\n",
       "      <td>Davis Cup G1 R1: TPE vs CHN</td>\n",
       "      <td>20170217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>2017-M-DC-2017-G1-AO-M-TPE-CHN-01</td>\n",
       "      <td>Davis Cup G1 R1: TPE vs CHN</td>\n",
       "      <td>20170217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2017-M-DC-2017-G2-EPA-M-SWE-TUN-01</td>\n",
       "      <td>Davis Cup G2 R1: SWE vs TUN</td>\n",
       "      <td>20170203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2017-M-DC-2017-G2-EPA-M-TUR-CYP-01</td>\n",
       "      <td>Davis Cup G2 R1: TUR vs CYP</td>\n",
       "      <td>20170203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tourney_id                 tourney_name  \\\n",
       "1840   2017-M-DC-2017-G1-AO-M-TPE-CHN-01  Davis Cup G1 R1: TPE vs CHN   \n",
       "1841   2017-M-DC-2017-G1-AO-M-TPE-CHN-01  Davis Cup G1 R1: TPE vs CHN   \n",
       "1842   2017-M-DC-2017-G1-AO-M-TPE-CHN-01  Davis Cup G1 R1: TPE vs CHN   \n",
       "2010  2017-M-DC-2017-G2-EPA-M-SWE-TUN-01  Davis Cup G2 R1: SWE vs TUN   \n",
       "2011  2017-M-DC-2017-G2-EPA-M-TUR-CYP-01  Davis Cup G2 R1: TUR vs CYP   \n",
       "\n",
       "      tourney_date surface  \n",
       "1840      20170217     NaN  \n",
       "1841      20170217     NaN  \n",
       "1842      20170217     NaN  \n",
       "2010      20170203     NaN  \n",
       "2011      20170203     NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display 5 matches that had a missing value for surface\n",
    "df[df.surface.isnull()].head(5)[['tourney_id','tourney_name','tourney_date','surface']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the surface to \"Hard\" for a specific match\n",
    "df.loc[df.tourney_id == \"2017-M-DC-2017-G1-AO-M-TPE-CHN-01\", 'surface'] = \"Hard\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then filled in many of the missing values for players' heights and ages, which was a lot of manual work. I've again omitted the code for this to keep the notebook concise, but see below for 2 lines of sample code. I calculated age values using the player's birthdate and the tournament start date. After a while, it was taking too long to manually find all of the missing heights online, so I filled the rest of them with the mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of how I filled in player ages\n",
    "df.loc[(df.loser_name == \"Christopher Eubanks\") & (df.tourney_date == 20170724), 'loser_age'] = 21.219178\n",
    "\n",
    "# Example of how I filled in player heights\n",
    "df.loc[df.winner_id == 105430, 'winner_ht'] = 175\n",
    "\n",
    "# Fill in the remaining missing heights by using the mean value\n",
    "df.winner_ht.fillna(value = df.winner_ht.mean(), inplace = True)\n",
    "df.loser_ht.fillna(value = df.loser_ht.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to check each variable and see if there were any improbable values which could have indicated errors. Whilst doing this, I noticed that many matches lasted less than 30 minutes. This obviously rang some alarm bells, since the shortest mens ATP tennis matches ever player lasted 28 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>5-3 RET</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6-1 RET</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>5-0 RET</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>3-0 RET</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>6-1 1-0 RET</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score  minutes\n",
       "297      5-3 RET     29.0\n",
       "578      6-1 RET     17.0\n",
       "580      5-0 RET     12.0\n",
       "676      3-0 RET     12.0\n",
       "919  6-1 1-0 RET     28.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the score and minutes of some of the matches that were shorter than 30 minutes\n",
    "df[df.minutes < 30].head()[['score','minutes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, I realised that some matches had ended by a player retiring (usually due to injury), which explained why so many matches' durations were so short. These incomplete matches were not useful for my analysis and modelling, so I deleted them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of matches that ended due to a player retiring\n",
    "df = df[df.score.str.find('RET') == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also noticed that in some matches, the string representing the score contained letters. These matches were investigated as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = set('0123456789- ()')\n",
    "for index,row in df.iterrows():\n",
    "    if not set(row.score).issubset(allowed_chars):\n",
    "        print [row.score, index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident from the output, these matches involved a default (e.g. for a rule violation) or walkover (when a player forfeits the match). I got rid of these incomplete matches, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = set(\"0123456789- ()\")\n",
    "for index,row in df.iterrows():\n",
    "    if not set(row.score).issubset(allowed_chars):\n",
    "        df.drop(index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked to see if any more matches had durations of less than 28 minutes, and found that some of the scores were incomplete, yet hadn't been marked as retired matches, defaults or walk-overs, e.g. one score was \"4-1\". I deleted these rows. I also found that certain matches had very short durations, even though they had a complete score. E.g. one match lasted 5 sets, yet apparently lasted only 27 minutes, which was obviously an error. These matches weren't an issue though, since I didn't intend to use the _minutes_ variable in my model - it was just a useful tool to identify errors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the 'minutes' variable\n",
    "df.drop('minutes', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Next, I began doing some feature engineering. This included:\n",
    "- Parsing the string variable 'score'. This function takes in a string representing a legitimate tennis scoreline and returns the percentage of games won by each player, as well as the total games played in the match\n",
    "- Creating features representing the percentage of games won for each player (using the score parser)\n",
    "- Creating features representing the percentage of points won whilst on serve for each player\n",
    "- Creating features representing the percentage of points won whilst returning for each player\n",
    "- Creating features representing the percentage of break points won for each player\n",
    "- Creating features representing the ace percentage and double-fault percentage for each player\n",
    "\n",
    "These percentage features provide a better estimation for how well players performed in different aspects of the match, compared to the raw counts. The number of games won by each player wasn't provided in the dataset, so I created a score parser to extract this useful information. The break-point-won percentages provide insight into how well the players performed in critical moments of the match (i.e. how well they saved break points and how well they capitalised on the opportunity to break their opponent's serve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to parse the score variable. \n",
    "'''\n",
    "Takes in a string representing a tennis scoreline. \n",
    "Returns the percentage of games won by each player as well as the total number of games played in the match\n",
    "'''\n",
    "def parse_score(score):\n",
    "    winner_gms = 0\n",
    "    loser_gms = 0\n",
    "    i = 0\n",
    "    while i < len(score):        \n",
    "        temp = int(score[i])\n",
    "        i+=1\n",
    "        if score[i].isdigit():\n",
    "            winner_gms+= (temp * 10 + int(score[i]))\n",
    "            i+=2\n",
    "        else:\n",
    "            winner_gms += temp\n",
    "            i += 1\n",
    "        temp = int(score[i])\n",
    "        i+=1\n",
    "        if i< len(score) and score[i].isdigit():\n",
    "            loser_gms += (temp * 10 + int(score[i]))\n",
    "            i+=1\n",
    "        else:\n",
    "            loser_gms += temp     \n",
    "        if i < len(score):\n",
    "            if score[i] == \"(\":\n",
    "                while score[i] != \")\":\n",
    "                    i+=1\n",
    "                i+=2\n",
    "            else:\n",
    "                i+=1\n",
    "    total_gms = float(winner_gms + loser_gms)\n",
    "    return [(winner_gms/total_gms)*100, (loser_gms/total_gms)*100, total_gms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of games won by each player in that match\n",
    "df['w_gmsWon_pct'] = df.apply(lambda x: parse_score(x['score'])[0], axis = 1)\n",
    "df['l_gmsWon_pct'] = df.apply(lambda x: parse_score(x['score'])[1], axis = 1)   \n",
    "\n",
    "# Calculate both players' ace and double-fault percentages\n",
    "df['w_ace_pct'] = (df['w_ace']/df.w_svpt) * 100\n",
    "df['l_ace_pct'] = (df['l_ace']/df.l_svpt) * 100\n",
    "\n",
    "df['w_df_pct'] = (df['w_df']/df['w_svpt']) * 100\n",
    "df['l_df_pct'] = (df['l_df']/df['l_svpt']) * 100\n",
    "\n",
    "# Calculate both players' win-on-serve, win-on-return and win-on-break-point percentages\n",
    "\n",
    "df['w_serve_pts_pct'] = (df['w_1stWon'] + df['w_2ndWon'])/(df['w_svpt'])*100\n",
    "df['l_serve_pts_pct'] = (df['l_1stWon'] + df['l_2ndWon'])/(df['l_svpt'])*100\n",
    "\n",
    "df['w_retpts_pct'] = (df['l_svpt'] - df['l_1stWon'] - df['l_2ndWon'])/(df['l_svpt'])*100\n",
    "df['l_retpts_pct'] = (df['w_svpt'] - df['w_1stWon'] - df['w_2ndWon'])/(df['w_svpt'])*100\n",
    "\n",
    "df['w_bpWon_pct'] = (df.w_bpSaved + df.l_bpFaced - df.l_bpSaved)/(df.w_bpFaced + df.l_bpFaced)*100\n",
    "df['l_bpWon_pct'] = (df.l_bpSaved + df.w_bpFaced - df.w_bpSaved)/(df.l_bpFaced + df.w_bpFaced)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After the creation of the new variables, I checked again for missing values. I saw that there were a few missing values in the new variables, which must have occurred because of a division by 0 (due to certain original features having been incorrectly recorded as having values of 0). I dropped those rows that had missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hard      31136\n",
       "Clay      21096\n",
       "Grass      6812\n",
       "Carpet     3490\n",
       "Name: surface, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print unique values of the 'surface' variable, with corresponding frequencies\n",
    "df['surface'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'grass' and 'carpet' surface values didn't have many samples, which could have caused some issues later on in my processing. Furthermore, carpet is a very similar playing surface to grass (known from my research and general knowledge of tennis). As such, I set all 'carpet' surface values to 'grass'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.surface == 'Carpet', 'surface'] = 'Grass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data cleaning was complete, I saved the data to a new csv file called \"atp_matches5.csv\" which will be used in the next stages of the project. \n",
    "\n",
    "At this stage, I had a dataset where each row provided match statistics (including player performance metrics) of a particular match. The aim of this project was to create a model that can predict the winner of a match, so I had to create a dataset where each row, representing a match, had columns that estimate various abilities of the players (e.g. their ability to win points on their serve, their ability to win break points, etc) at the time before the match was played.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate these player characteristics, I calculated weighted averages (weighted by time, opponent ranking and playing surface) of each of the original variables from the players' past 40 matches. A rough outline of the algorithm I used is given below:\n",
    "\n",
    "- For each row in the dataset, with surface _s_:\n",
    "  - For each player (i.e. the winner and loser) in the row:\n",
    "    - Find the last 40 matches that the player played in, of which at least 10 were played on surface _s_\n",
    "    - For each feature in {serve_pts_pct, retpts_pct, ace_pct, bpWon_pct, gmsWon_pct}:\n",
    "      - Find the average value of the feature from the set of 40 matches, weighted by how long ago the match took place, the opponent rank and the surface it was played on \n",
    "    - Calculate the percentage of matches the player won out of these last 40 matches, adjusted for how long ago each match took place, the opponent rank and the surface it was played on\n",
    "    - Add the new features to the dataframe\n",
    "    \n",
    "See below for the code I used.\n",
    "\n",
    "**NOTE: The calculate() function was originally cobbled together poorly. It will be re-written in the future to make use of vectorization (for greatly increased speed) and modularisation (to improve readability and maintainance)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"atp_matches5.csv\", usecols=range(32), index_col = False)\n",
    "\n",
    "# Create new variable called 'index' that will be used later on\n",
    "df['index'] = df.index\n",
    "\n",
    "# Get rid of matches that were played before 1999 (to reduce the size of the dataset)\n",
    "df = df[df.tourney_date > 19990000]\n",
    "df.tourney_date = df.tourney_date.astype(str)\n",
    "\n",
    "# Create new variables\n",
    "df['w_ave_svpt_pct'] = np.nan\n",
    "df['w_ave_retpt_pct'] = np.nan\n",
    "df['w_ave_bpWon_pct'] = np.nan\n",
    "df['w_ave_ace_pct'] = np.nan\n",
    "df['w_ave_gmsWon_pct'] = np.nan\n",
    "df['w_win_pct'] = np.nan\n",
    "\n",
    "# Takes in two strings representing dates, outputs number of years between the dates\n",
    "def yrs_between(start, end):\n",
    "    yrs = int(end[:4]) - int(start[:4])\n",
    "    mths = (int(end[4:6]) - int(start[4:6]))/12.0\n",
    "    days = (int(end[6:8]) - int(start[6:8]))/365.0\n",
    "    return yrs + mths + days\n",
    "\n",
    "# Calculates the weighting to be applied to a match played a certain number of years ago\n",
    "def time_discount(time):\n",
    "    return min(0.6**time,0.6)\n",
    "\n",
    "# Functions used to calculate weightings for matches given the opponent's ranking\n",
    "def opp_weight(opp_rank):\n",
    "    return max(-0.8*opp_rank/299 + 1.4027, 0.6)\n",
    "\n",
    "def l_opp_weight(opp_rank):\n",
    "    return min(0.8*opp_rank/299 + 0.6, 1.4)\n",
    "\n",
    "# Function to set the values of the new variables\n",
    "\n",
    "def calculate():\n",
    "    df_min = df[['tourney_date','surface','index','winner_id','loser_id','winner_rank','loser_rank','w_serve_pts_pct','w_retpts_pct',\n",
    "    'w_bpWon_pct','w_ace_pct','w_gmsWon_pct', 'l_serve_pts_pct','l_retpts_pct','l_bpWon_pct','l_ace_pct','l_gmsWon_pct']]\n",
    "    \n",
    "    for row in df_min.itertuples():\n",
    "      surface = row[2]\n",
    "      serve_pts = 0\n",
    "      ret_pts = 0\n",
    "      bpWon = 0\n",
    "      ace = 0\n",
    "      gmsWon = 0\n",
    "      match_pct = 0\n",
    "      total_weight = 0\n",
    "      match_weight = 0\n",
    "\n",
    "      df_temp = df_min[((df_min.winner_id == row[4]) | (df_min.loser_id == row[4]))].loc[row[3] + 1:]\n",
    "    \n",
    "      if len(df_temp) < 40:\n",
    "        df.drop(row[3], inplace = True)\n",
    "        continue\n",
    "      \n",
    "      df_s = df_temp[df_temp['surface'] == surface].head(10)\n",
    "      if len(df_s) < 10:\n",
    "        df.drop(row[3], inplace = True)\n",
    "        continue\n",
    "      \n",
    "      for match in df_s.itertuples():\n",
    "          df_temp.drop(match[3], inplace = True) \n",
    "          if match[4] == row[4]:\n",
    "            weight = 2 * time_discount(yrs_between(match[1],row[1]))\n",
    "            multiplier = weight * opp_weight(match[7])\n",
    "            serve_pts += (match[8] * multiplier)\n",
    "            ret_pts += (match[9] * multiplier)\n",
    "            bpWon += (match[10] * multiplier)\n",
    "            ace += (match[11] * multiplier)\n",
    "            gmsWon += (match[12] * multiplier)\n",
    "            match_pct += (multiplier)\n",
    "            total_weight+= weight\n",
    "            match_weight += weight\n",
    "          else:\n",
    "            weight = 2 * time_discount(yrs_between(match[1],row[1]))\n",
    "            multiplier = weight * opp_weight(match[6])\n",
    "            serve_pts += (match[13] * multiplier)\n",
    "            ret_pts += (match[14] * multiplier)\n",
    "            bpWon += (match[15] * multiplier)\n",
    "            ace += (match[16] * multiplier)\n",
    "            gmsWon += (match[17] * multiplier)\n",
    "            total_weight+= weight\n",
    "            match_weight += (weight*l_opp_weight(match[6]))\n",
    "\n",
    "\n",
    "      for match in df_temp.head(30).itertuples():\n",
    "          if match[4] == row[4]:\n",
    "              weight = time_discount(yrs_between(match[1],row[1]))\n",
    "              multiplier = weight * opp_weight(match[7])\n",
    "              serve_pts += (match[8] * multiplier)\n",
    "              ret_pts += (match[9] * multiplier)\n",
    "              bpWon += (match[10] * multiplier)\n",
    "              ace += (match[11] * multiplier)\n",
    "              gmsWon += (match[12] * multiplier)\n",
    "              match_pct += (multiplier)\n",
    "              total_weight+= weight\n",
    "              match_weight += weight\n",
    "          else:\n",
    "            weight = time_discount(yrs_between(match[1],row[1]))\n",
    "            multiplier = weight * opp_weight(match[6])\n",
    "            serve_pts += (match[13] * multiplier)\n",
    "            ret_pts += (match[14] * multiplier)\n",
    "            bpWon += (match[15] * multiplier)\n",
    "            ace += (match[16] * multiplier)\n",
    "            gmsWon += (match[17] * multiplier)\n",
    "            total_weight+= weight\n",
    "            match_weight += (weight*l_opp_weight(match[6]))\n",
    "      df.at[row[3], 'w_ave_svpt_pct']= (serve_pts/total_weight)\n",
    "      df.at[row[3], 'w_ave_retpt_pct']= (ret_pts/total_weight)\n",
    "      df.at[row[3], 'w_ave_bpWon_pct']= (bpWon/total_weight)\n",
    "      df.at[row[3], 'w_ave_ace_pct']= (ace/total_weight)\n",
    "      df.at[row[3], 'w_ave_gmsWon_pct']= (gmsWon/total_weight)\n",
    "      df.at[row[3], 'w_win_pct']= (match_pct/match_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: The calculate() function above was originally cobbled together poorly. It will be re-written in the future to make use of vectorization (for greatly increased speed) and modularisation (to improve readability and maintainance)**\n",
    "\n",
    "Because of this, executing the next code cell may take a long time. \n",
    "However, there is no need to run the cell, since its output was saved to csv files that will be loaded and used in the next stage of the workbook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the function\n",
    "calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the calculate() function on the dataframe and saved the modified data to a file called \"atp_matches10.csv\". Then, I modified the function slightly to calculate the feature values for the matches losers, and ran it, saving the data to a file called \"atp_matches11.csv\".\n",
    "\n",
    "Now I had data that was almost ready to be used to train our machine learning algorithms. However, there were a few more processing steps to do. \n",
    "\n",
    "Firstly, I needed to merge the two csv files together to obtain a single dataset that contained both the winner statistics and loser statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the 2 dataframes\n",
    "\n",
    "df1 = pd.read_csv(\"atp_matches10.csv\", usecols=range(39), index_col = False)\n",
    "df2 = pd.read_csv(\"atp_matches11.csv\", usecols=range(39), index_col = False)\n",
    "\n",
    "df1 = df1[['surface','tourney_level','winner_hand','winner_ht','winner_age','winner_rank_points','loser_hand','loser_ht',\n",
    "          'loser_age','loser_rank_points','best_of','stage', 'w_ave_svpt_pct','w_ave_retpt_pct','w_ave_bpWon_pct','w_ave_ace_pct',\n",
    "           'w_ave_gmsWon_pct','w_win_pct','index']]\n",
    "\n",
    "df2 = df2[['surface','tourney_level','winner_hand','winner_ht','winner_age','winner_rank_points','loser_hand','loser_ht',\n",
    "          'loser_age','loser_rank_points','best_of','stage', 'l_ave_svpt_pct','l_ave_retpt_pct','l_ave_bpWon_pct','l_ave_ace_pct',\n",
    "           'l_ave_gmsWon_pct','l_win_pct','index']]\n",
    "\n",
    "df3 = pd.merge(df1, df2, on='index', how = 'inner', suffixes=('', '_y'))\n",
    "\n",
    "# Define a function to get rid of duplicate columns\n",
    "def drop_y(dataframe):\n",
    "    to_drop = [x for x in dataframe if x.endswith('_y')]\n",
    "    dataframe.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "# Get rid of duplicate columns  \n",
    "drop_y(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the above cell was saved to \"atp_matches12.csv\". Next, I encoded the categorical variables. After that, the last data processing step was to create a response variable which indicates which player won the match. I created new variables for each player performance feature, generated a random number to assign either player 1 or player 2 as the winner, and set the new feature values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"atp_matches12.csv\", usecols=range(25), index_col = False)\n",
    "\n",
    "# Encode categorical variables\n",
    "mapping_dict = {\n",
    "    \"surface\": {\n",
    "        \"Clay\": 0,\n",
    "        \"Hard\": 1,\n",
    "        \"Grass\": 2\n",
    "        },\n",
    "    \"tourney_level\": {\n",
    "        \"A\": 0,\n",
    "        \"D\": 1,\n",
    "        \"M\": 2,\n",
    "        \"F\": 3,\n",
    "        \"G\": 4\n",
    "    },\n",
    "    \"winner_hand\": {\n",
    "        \"R\": 0,\n",
    "        \"L\": 1\n",
    "        }\n",
    "}\n",
    "df = df.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random number for each match, indicating whether \"player 1\" or \"player 2\" won the match\n",
    "import random\n",
    "for i in range(30118):\n",
    "    x = random.randint(1,2)\n",
    "    # If x = 1, then player 1 won\n",
    "    if x == 1:\n",
    "        df.at[i, 'winner'] = 1\n",
    "        # Replace 'winner_' with 'p1_'\n",
    "        # Replace 'loser_' with 'p2_'\n",
    "        df.at[i, 'p1_hand'] = df.loc[i]['winner_hand']\n",
    "        df.at[i, 'p1_ht'] = df.loc[i]['winner_ht']\n",
    "        df.at[i, 'p1_age'] = df.loc[i]['winner_age']\n",
    "        df.at[i, 'p1_rank_points'] = df.loc[i]['winner_rank_points']\n",
    "        df.at[i, 'p1_ave_svpt_pct'] = df.loc[i]['w_ave_svpt_pct']\n",
    "        df.at[i, 'p1_ave_retpt_pct'] = df.loc[i]['w_ave_retpt_pct']\n",
    "        df.at[i, 'p1_ave_bpWon_pct'] = df.loc[i]['w_ave_bpWon_pct']\n",
    "        df.at[i, 'p1_ave_ace_pct'] = df.loc[i]['w_ave_ace_pct']\n",
    "        df.at[i, 'p1_ave_gmsWon_pct'] = df.loc[i]['w_ave_gmsWon_pct']        \n",
    "        df.at[i, 'p1_win_pct'] = df.loc[i]['w_win_pct']\n",
    "        \n",
    "        df.at[i, 'p2_hand'] = df.loc[i]['loser_hand']\n",
    "        df.at[i, 'p2_ht'] = df.loc[i]['loser_ht']\n",
    "        df.at[i, 'p2_age'] = df.loc[i]['loser_age']\n",
    "        df.at[i, 'p2_rank_points'] = df.loc[i]['loser_rank_points']\n",
    "        df.at[i, 'p2_ave_svpt_pct'] = df.loc[i]['l_ave_svpt_pct']\n",
    "        df.at[i, 'p2_ave_retpt_pct'] = df.loc[i]['l_ave_retpt_pct']\n",
    "        df.at[i, 'p2_ave_bpWon_pct'] = df.loc[i]['l_ave_bpWon_pct']\n",
    "        df.at[i, 'p2_ave_ace_pct'] = df.loc[i]['l_ave_ace_pct']\n",
    "        df.at[i, 'p2_ave_gmsWon_pct'] = df.loc[i]['l_ave_gmsWon_pct']        \n",
    "        df.at[i, 'p2_win_pct'] = df.loc[i]['l_win_pct']\n",
    "        \n",
    "    # If x = 2, then player 2 won\n",
    "    else:\n",
    "        # Replace 'winner_' with 'p2_'\n",
    "        # Replace 'loser_' with 'p1_'\n",
    "        df.at[i, 'winner'] = 2\n",
    "        \n",
    "        df.at[i, 'p2_hand'] = df.loc[i]['winner_hand']\n",
    "        df.at[i, 'p2_ht'] = df.loc[i]['winner_ht']\n",
    "        df.at[i, 'p2_age'] = df.loc[i]['winner_age']\n",
    "        df.at[i, 'p2_rank_points'] = df.loc[i]['winner_rank_points']\n",
    "        df.at[i, 'p2_ave_svpt_pct'] = df.loc[i]['w_ave_svpt_pct']\n",
    "        df.at[i, 'p2_ave_retpt_pct'] = df.loc[i]['w_ave_retpt_pct']\n",
    "        df.at[i, 'p2_ave_bpWon_pct'] = df.loc[i]['w_ave_bpWon_pct']\n",
    "        df.at[i, 'p2_ave_ace_pct'] = df.loc[i]['w_ave_ace_pct']\n",
    "        df.at[i, 'p2_ave_gmsWon_pct'] = df.loc[i]['w_ave_gmsWon_pct']\n",
    "        df.at[i, 'p2_win_pct'] = df.loc[i]['w_win_pct']\n",
    "        \n",
    "        df.at[i, 'p1_hand'] = df.loc[i]['loser_hand']\n",
    "        df.at[i, 'p1_ht'] = df.loc[i]['loser_ht']\n",
    "        df.at[i, 'p1_age'] = df.loc[i]['loser_age']\n",
    "        df.at[i, 'p1_rank_points'] = df.loc[i]['loser_rank_points']\n",
    "        df.at[i, 'p1_ave_svpt_pct'] = df.loc[i]['l_ave_svpt_pct']\n",
    "        df.at[i, 'p1_ave_retpt_pct'] = df.loc[i]['l_ave_retpt_pct']\n",
    "        df.at[i, 'p1_ave_bpWon_pct'] = df.loc[i]['l_ave_bpWon_pct']\n",
    "        df.at[i, 'p1_ave_ace_pct'] = df.loc[i]['l_ave_ace_pct']\n",
    "        df.at[i, 'p1_ave_gmsWon_pct'] = df.loc[i]['l_ave_gmsWon_pct']\n",
    "        df.at[i, 'p1_win_pct'] = df.loc[i]['l_win_pct'] \n",
    "        \n",
    "# Get rid of variables that are no longer needed\n",
    "df = df[['surface','tourney_level','winner','p1_hand','p1_ht','p1_age','p1_rank_points','p2_hand','p2_ht',\n",
    "          'p2_age','p2_rank_points','best_of','stage', 'p1_ave_svpt_pct','p1_ave_retpt_pct','p1_ave_bpWon_pct','p1_ave_ace_pct',\n",
    "           'p1_ave_gmsWon_pct','p1_win_pct','p2_ave_svpt_pct','p2_ave_retpt_pct','p2_ave_bpWon_pct','p2_ave_ace_pct',\n",
    "           'p2_ave_gmsWon_pct','p2_win_pct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "\n",
    "The next stage of the project was to train machine learning classification algorithms. I began by quickly trying out some simple algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "# Separate the features from the response variable \n",
    "\n",
    "features = [x for x in df.columns.tolist() if x != 'winner']\n",
    "response = 'winner'\n",
    "X = df[features]\n",
    "Y = df[response]\n",
    "\n",
    "# Split the data into a training set and testing set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train a Decision Tree Classifier with the training data\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 58.411%\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the match winner of records in the test set \n",
    "y_predict = dt.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score of the classifier\n",
    "print \"Accuracy score: \" + str(round(accuracy_score(y_test, y_predict)*100, 3)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 58.4% is quite poor, so I decided to try out other machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Train a k-Nearest Neighbours classifier with the training data\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 60.015%\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions and calculate the accuracy score of the model\n",
    "\n",
    "y_predict = neigh.predict(X_test)\n",
    "print \"Accuracy score: \" + str(round(accuracy_score(y_test, y_predict)*100, 3)) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 67.773%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a Logistic Regression model with the training data\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions and calculate the accuracy score of the model\n",
    "\n",
    "y_predict = logreg.predict(X_test)\n",
    "print \"Accuracy score: \" + str(round(accuracy_score(y_test, y_predict)*100, 3)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The prediction results varied from poor to fairly good - the Logistic Regression model was reasonably accurate. However, even its prediction accuracy of just under 68% was a little disappointing. The model could be improved by:\n",
    "\n",
    " - Standardising the features\n",
    " - Using a feature selection algorithm\n",
    " - Tuning the model parameters\n",
    " - Using ensemble methods (such as random forests, bagging, boosting, etc)\n",
    "\n",
    "Even though the results weren't as impressive as I'd hoped for, I learnt a lot by completing this project, and believe that by refining some of the data processing and modelling techniques that I used, much better models can be created to predict the outcome of ATP tennis matches. I hope to continue this project in in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
